roadmap for language learning

translation exercise - koniecznośc wypisania wszystkich form (oddzielonych spacją lub przecinkami). wtedy "correct" nie musi ich podawać

slowo polskie jako tlumaczenie lacinskiego. jeśli tłumaczen jest wiele trzeba podac wszystkie (liczba moze byc podpowiedziana)

odpytywanie o rozne formy - np slowo polskie ale w supinum

znajdywanie duplikatów w słowniku

random word powinno losować dane z tej samej bazy co translation ex (w opcji smart)

sprawdzac jakie slowa sa ze soba najczesciej mylone

option to filter part of speech (translation and random word)

option to filter only new or not mastered words

option to filter only top X (count, not percentage)

do testow scrapingu dodac: altus, bonus, cogito, inimicus, inter, centum, unus

zrobic wlasna baze dla kilku tysiecy najczestszych slow

uzywajac latin online dict mozna pytac o deklinacje/koniugacje dla dowolnego slowa ze slownika

kazda deklinacje, koniugacje testowac w dwie strony - z podenj formy podawac slowo, ale tez ze slowa wszystkie formy ktore mu odpowiadaja

declension, conjugation: -r will remove after correct answer

translation exercise: from latin to polish

podać czasownik i zapytać o jego formę (mood, tense, voice, person, nr)

scrape'ing: usuwanie duplikatów z argumentów wejściowych (albo opcja dodawania zdania)

usuwanie duplikatów z wyników scrape'owania

może przykłady w słowniku powinny być opcjonalne ?

deepl glossary https://www.deepl.com/pl/docs-api/glossaries/list-glossaries/ - could be better than elastic / mongo db

ukryć klucz do API deepl

dodac infinitivus praesentis passivi do conjugation.json

dodac esse

jak zadziala smart sampling w przypadku filtrowania (podzbiory wyrazow) ?

w każdym skrypcie - filtrowanie tylko pewnych części mowy (trzeba tez filtrowac baze)

symulowac przeciwnikow dla RL w grze w zgadywanie slow. tzn. rozne modele pamieci i zadanie dla RL zeby nauczyc sie uzyskiwac jak najwyzsze rezultaty przeciwko nim
jakiekolwiek explainable ai dla takich modeli ? w ten sposob mozna by modelowac pamiec roznych osob

niektóre tłumaczenia nie są unikalne. np et, atque, nec non

test na parsowanie slownika - czy nie ma typu none. albo rzucanie wyjatku kiedy nie uda sie czegos sparsowac. zrobic test automatyczny

walidacja, czy kazde slowo ma przyklad w "()"

skrypt do wypisywania samych slow (podstawowa forma)

skrypt do wypisywania samych znaczen (pierwsze tlumaczenie)

pytac o znaczenie slowa - wystarczy podac jedno, traktujac slowa oddzielone przecinkiem jako osobne, nie troszczac sie o polskie znaki

pytac o forme podstawowa, inf, perf, sup

tracking user's difficulties (profiles, database, tracking previous progress) and personalizing questions
also calculating statistics (how memory user has ? how often one should remind him words which were not asked recently ? performance vs frequency)
github pipeline for running pytest (and mypy) and updating requirements.txt
github packages, docker, pylint https://github.blog/2022-02-02-build-ci-cd-pipeline-github-actions-four-steps/
web app with a few endpoints as a counterparts for runnable scripts ?
"how to use it" should be available in "help" option for all modules
validators for files
track how many times word appeared (and was removed if flag was set). used that info for weighting probabilities
for random words keep track of which were not removed when there was option to do so. with it may be written to csv file
take only recent tries under consideration for specifying distribution

z kazdego slowa brac pierwsze tlumaczenie; podawac je pytac o tlumaczenie na obcu jezyk (z tolerancja dla liter akcentowanych itp.)
wypisywac kilka slow; mozna z nich teraz ukladac zdania
brac tlumaczenie i kazac podac konkretna forme (np. supinum)
